#  Licensed to Elasticsearch B.V. under one or more contributor
#  license agreements. See the NOTICE file distributed with
#  this work for additional information regarding copyright
#  ownership. Elasticsearch B.V. licenses this file to you under
#  the Apache License, Version 2.0 (the "License"); you may
#  not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#
# 	http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.
import tempfile

import numpy as np
import pytest

try:
    import sklearn  # noqa: F401

    HAS_SKLEARN = True
except ImportError:
    HAS_SKLEARN = False

try:
    import transformers  # noqa: F401

    from eland.ml.pytorch import PyTorchModel
    from eland.ml.pytorch.transformers import TransformerModel

    HAS_TRANSFORMERS = True
except ImportError:
    HAS_TRANSFORMERS = False

from tests import ES_TEST_CLIENT, ES_VERSION

pytestmark = [
    pytest.mark.skipif(
        ES_VERSION < (8, 0, 0),
        reason="This test requires at least Elasticsearch version 8.0.0",
    ),
    pytest.mark.skipif(
        not HAS_SKLEARN, reason="This test requires 'scikit-learn' package to run"
    ),
    pytest.mark.skipif(
        not HAS_TRANSFORMERS, reason="This test requires 'transformers' package to run"
    ),
]

TEXT_PREDICTION_MODELS = [
    (
        "distilbert-base-uncased",
        "fill_mask",
        "[MASK] is the capital of France.",
        "paris",
    ),
    (
        "distilbert-base-uncased-finetuned-sst-2-english",
        "text_classification",
        "I love Elasticsearch",
        "POSITIVE",
    ),
    (
        "elastic/distilbert-base-cased-finetuned-conll03-english",
        "ner",
        "I am Bart Simpson and I work at Elastic.",
        "I am [Bart Simpson](PER&Bart+Simpson) and I work at [Elastic](ORG&Elastic).",
    ),
]

ZERO_SHOT_MODELS = [
    (
        "typeform/squeezebert-mnli",
        "Elasticsearch now supports PyTorch machine learning models for NLP.",
        ["technology", "politics", "sports"],
        "technology",
    ),
    (
        "typeform/distilbert-base-uncased-mnli",
        "Elasticsearch is the distributed, RESTful search and analytics engine at the heart of the Elastic Stack. You "
        "can use Elasticsearch to store, search, and manage data.",
        ["sports", "technology", "politics", "popular"],
        "technology",
    ),
]

TEXT_EMBEDDING = [
    (
        False,
        "sentence-transformers/all-MiniLM-L12-v2",
        "Elasticsearch is the distributed, RESTful search and analytics engine at the heart of the Elastic Stack. You "
        "can use Elasticsearch to store, search, and manage data.",
        [
            0.0037712352350354195,
            -0.030481912195682526,
            -0.03365401178598404,
            -0.0001335958222625777,
            -0.00690954364836216,
            -0.02836783602833748,
            -0.05146409943699837,
            0.05952649191021919,
            0.020197756588459015,
            0.03895943611860275,
            0.004077147226780653,
            0.026496144011616707,
            -0.02277253568172455,
            0.005767420865595341,
            -0.018845925107598305,
            0.034084320068359375,
            0.004399542696774006,
            0.0316573865711689,
            0.004155017901211977,
            -0.09351115673780441,
            0.06918929517269135,
            0.039492979645729065,
            0.009238188154995441,
            -0.07573536038398743,
            -0.01426721177995205,
            -0.009398194029927254,
            -0.036571163684129715,
            0.01612229086458683,
            -0.042382143437862396,
            -0.0068984548561275005,
            0.09683021157979965,
            -0.0187432412058115,
            0.11261739581823349,
            0.04001711308956146,
            -0.02951154112815857,
            0.030622316524386406,
            -0.012094789184629917,
            -0.01963229663670063,
            -0.04858902096748352,
            -0.01174047589302063,
            0.02892044372856617,
            -0.017641479149460793,
            -0.0437215194106102,
            0.02210555039346218,
            -0.0015220753848552704,
            0.020085811614990234,
            -0.004508133977651596,
            0.012043925933539867,
            -0.01804201304912567,
            -0.040649257600307465,
            -0.040280021727085114,
            0.020468570291996002,
            0.016827916726469994,
            -0.0507950522005558,
            0.010143174789845943,
            0.08644240349531174,
            0.07957837730646133,
            -0.05301407724618912,
            -0.024896997958421707,
            -0.05797343701124191,
            0.11501969397068024,
            0.029073162004351616,
            0.0051078530959784985,
            0.009118665009737015,
            -0.0912148728966713,
            0.014023243449628353,
            -0.029612815007567406,
            0.04628580063581467,
            0.07040295004844666,
            -0.07557704299688339,
            0.06818722188472748,
            -0.014259464107453823,
            -0.04523153230547905,
            0.07238060235977173,
            -0.009485247544944286,
            0.008597194217145443,
            0.09068455547094345,
            -0.05969524756073952,
            0.07476720958948135,
            0.030170630663633347,
            -0.057958755642175674,
            -0.03830433636903763,
            -0.016067931428551674,
            -0.04489272087812424,
            -0.012557834386825562,
            -0.08076123893260956,
            -0.03559476137161255,
            -0.054170262068510056,
            0.05495510995388031,
            0.03465660288929939,
            0.0637698844075203,
            -0.003932842519134283,
            0.04610856994986534,
            -0.10064198076725006,
            -0.006727264728397131,
            0.016383139416575432,
            -0.05118856951594353,
            -0.008541851304471493,
            0.1048741415143013,
            -0.033692244440317154,
            -0.015009834431111813,
            0.054833605885505676,
            -0.030323438346385956,
            -0.01922871731221676,
            -0.004449940752238035,
            0.0009935521520674229,
            -0.053164709359407425,
            0.013289177790284157,
            0.00800948403775692,
            0.025207241997122765,
            0.03203672543168068,
            0.0159728042781353,
            -0.0019451469415798783,
            -0.025858378037810326,
            0.003811911214143038,
            -0.0007070595165714622,
            -0.06838871538639069,
            -0.02424040250480175,
            -0.03514431044459343,
            0.10322929918766022,
            -0.059738293290138245,
            -0.016767270863056183,
            0.04758531600236893,
            0.0053009409457445145,
            0.01585463434457779,
            0.06050555035471916,
            -0.02351142279803753,
            0.028913114219903946,
            0.0409059152007103,
            -0.037876591086387634,
            -0.02660094015300274,
            -0.07878168672323227,
            -0.10875652730464935,
            0.041324812918901443,
            -0.03852027654647827,
            0.06697846949100494,
            -0.07236555963754654,
            -0.060778431594371796,
            -0.023312076926231384,
            0.13566181063652039,
            0.05942463129758835,
            0.042442016303539276,
            0.011608626693487167,
            0.013611102476716042,
            0.0467606820166111,
            0.010652383789420128,
            0.009909585118293762,
            -0.1229449212551117,
            -0.0774649977684021,
            -0.08852176368236542,
            -0.02603425830602646,
            0.015660369768738747,
            0.014925223775207996,
            -0.006933133117854595,
            0.09392380714416504,
            -0.11864395439624786,
            0.029810357838869095,
            0.008116704411804676,
            0.012341981753706932,
            -0.057908281683921814,
            0.024246595799922943,
            0.005292652174830437,
            -0.04638510197401047,
            0.03164558485150337,
            -0.01783127151429653,
            0.023113351315259933,
            -0.021473081782460213,
            -0.04495728015899658,
            -0.0489838570356369,
            0.021811185404658318,
            0.07806515693664551,
            0.002124704187735915,
            -0.05481017008423805,
            -0.04687852784991264,
            -0.02297184243798256,
            0.021443545818328857,
            0.03264031559228897,
            0.0003128442622255534,
            0.04523957893252373,
            -0.1271415501832962,
            0.0671202689409256,
            -0.07674111425876617,
            0.039126113057136536,
            0.12357396632432938,
            0.00819889921694994,
            0.028351806104183197,
            -0.008366379886865616,
            0.03786984086036682,
            -0.03940378129482269,
            0.004199545830488205,
            0.08905965089797974,
            0.02636674791574478,
            0.13493403792381287,
            0.060356754809617996,
            0.04773511365056038,
            0.008691680617630482,
            -0.036999255418777466,
            0.004985872656106949,
            0.03408161550760269,
            0.018793860450387,
            -0.01333162933588028,
            0.08478252589702606,
            -0.01684817485511303,
            0.09032021462917328,
            -0.0340888537466526,
            0.04709931090474129,
            -0.008690912276506424,
            -0.0495891347527504,
            -0.05930714309215546,
            0.01009418535977602,
            0.049603551626205444,
            0.08210539072751999,
            0.02808409370481968,
            0.034355293959379196,
            -0.018834136426448822,
            -0.09677813947200775,
            -0.03237484395503998,
            -0.03555070608854294,
            -0.06383436918258667,
            0.03483237326145172,
            0.01714547537267208,
            0.0035199634730815887,
            -0.06165474280714989,
            7.85944926914588e-33,
            0.028866415843367577,
            -0.04647941514849663,
            -0.05888395383954048,
            0.07047773897647858,
            0.055506832897663116,
            0.0028398940339684486,
            0.040329258888959885,
            -0.06423458456993103,
            -0.011908282525837421,
            0.05020765960216522,
            -0.04150787740945816,
            -0.030940746888518333,
            0.11088748276233673,
            -0.04858129099011421,
            -0.10024851560592651,
            0.028600899502635002,
            -0.0047572338953614235,
            -0.09413924813270569,
            0.021019449457526207,
            0.005526501685380936,
            0.010176003910601139,
            -0.026425836607813835,
            0.01222997810691595,
            0.022507471963763237,
            -0.0018880009884014726,
            -0.0022913094144314528,
            0.05878821387887001,
            -0.08903750777244568,
            -0.0864739865064621,
            -0.03905723989009857,
            -0.046932462602853775,
            -0.05436200648546219,
            0.020368197932839394,
            -0.026840437203645706,
            0.025138165801763535,
            -0.016524475067853928,
            0.036324936896562576,
            -0.0899248942732811,
            -0.023870108649134636,
            -0.02322075329720974,
            0.03881451115012169,
            0.06106534227728844,
            0.04234654828906059,
            -0.022839650511741638,
            0.05618314445018768,
            0.046128541231155396,
            -0.05084122344851494,
            0.08304987102746964,
            -0.033476121723651886,
            -0.015991127118468285,
            -0.07135190069675446,
            0.09570572525262833,
            -0.06097591295838356,
            -0.011919123120605946,
            0.010229592211544514,
            0.05714195594191551,
            -0.0894802063703537,
            0.06984465569257736,
            -0.11130580306053162,
            0.08219874650239944,
            -0.025544853881001472,
            0.0000017220658037331305,
            -0.03961511328816414,
            0.11663887649774551,
            0.00991143099963665,
            0.02549632638692856,
            0.02792959101498127,
            -0.0560375452041626,
            -0.1255187839269638,
            0.036713678389787674,
            0.05951154977083206,
            -0.07247511297464371,
            0.052210014313459396,
            -0.016808222979307175,
            0.002298749517649412,
            0.012870670296251774,
            0.028170030564069748,
            0.03624413534998894,
            0.00646212650462985,
            0.011977734975516796,
            0.03474821895360947,
            0.05897247791290283,
            -0.019231434911489487,
            -0.00565249053761363,
            -0.0016013863496482372,
            0.032272014766931534,
            -0.009905013255774975,
            0.07812612503767014,
            0.0063345469534397125,
            0.007176761049777269,
            -0.024810222908854485,
            -0.13774797320365906,
            -0.15348905324935913,
            -0.06804517656564713,
            0.0785336121916771,
            2.1150058597282992e-32,
            -0.013892804272472858,
            0.05591318756341934,
            0.050703782588243484,
            -0.016834644600749016,
            0.027637803927063942,
            -0.033562108874320984,
            0.05419256538152695,
            0.11449886858463287,
            0.029707586392760277,
            -0.022709520533680916,
            0.07389979809522629,
            -0.07357893884181976,
            -0.10579443722963333,
            -0.007560309953987598,
            0.004672566428780556,
            0.010546407662332058,
            -0.03701718524098396,
            0.02584259770810604,
            -0.020555920898914337,
            -0.029343249276280403,
            -0.008900263346731663,
            -0.006442338693886995,
            0.07320588082075119,
            -0.001093558152206242,
            0.060992028564214706,
            -0.008974148891866207,
            0.004197342786937952,
            -0.009920436888933182,
            -0.025736892595887184,
            -0.0724557638168335,
            -0.0020025083795189857,
            0.07366622239351273,
            0.040275849401950836,
            0.03316127508878708,
            -0.000025899140382534824,
            0.07468714565038681,
            0.03121902421116829,
            -0.009058235213160515,
            -0.03177209943532944,
            0.07971727848052979,
            0.040641337633132935,
            0.11953351646661758,
            -0.03250516951084137,
            -0.022773459553718567,
            -0.06430361419916153,
            0.06316282600164413,
            0.035190682858228683,
            -0.04853269085288048,
            0.0500844307243824,
            -0.04704730212688446,
            -0.02760794386267662,
            -0.049474384635686874,
            0.037018924951553345,
            0.008347260765731335,
            0.004771129228174686,
            0.00255514495074749,
            -0.000719240284524858,
            -0.10453514009714127,
            0.0712762326002121,
            0.002318795770406723,
            0.04635736718773842,
            -0.07783054560422897,
            0.035038504749536514,
            -0.05477318540215492,
        ],
    )
]


@pytest.fixture(scope="function", autouse=True)
def setup_and_tear_down():
    ES_TEST_CLIENT.cluster.put_settings(
        body={"transient": {"logger.org.elasticsearch.xpack.ml": "DEBUG"}}
    )
    yield
    for model_id, _, _, _ in TEXT_PREDICTION_MODELS:
        model = PyTorchModel(ES_TEST_CLIENT, model_id.replace("/", "__").lower()[:64])
        model.stop()
        model.delete()

    for _, model_id, _, _ in TEXT_EMBEDDING:
        model = PyTorchModel(ES_TEST_CLIENT, model_id.replace("/", "__").lower()[:64])
        model.stop()
        model.delete()

    for model_id, _, _, _ in ZERO_SHOT_MODELS:
        model = PyTorchModel(ES_TEST_CLIENT, model_id.replace("/", "__").lower()[:64])
        model.stop()
        model.delete()


def download_model_and_start_deployment(tmp_dir, quantize, model_id, task):
    print("Loading HuggingFace transformer tokenizer and model")
    tm = TransformerModel(model_id, task, quantize)
    model_path, config_path, vocab_path = tm.save(tmp_dir)
    ptm = PyTorchModel(ES_TEST_CLIENT, tm.elasticsearch_model_id())
    ptm.stop()
    ptm.delete()
    print(f"Importing model: {ptm.model_id}")
    ptm.import_model(model_path, config_path, vocab_path)
    ptm.start()
    return ptm


class TestPytorchModel:
    @pytest.mark.parametrize("model_id,task,text_input,value", TEXT_PREDICTION_MODELS)
    def test_text_classification(self, model_id, task, text_input, value):
        with tempfile.TemporaryDirectory() as tmp_dir:
            ptm = download_model_and_start_deployment(tmp_dir, True, model_id, task)
            result = ptm.infer({"docs": [{"text_field": text_input}]})
            assert result["predicted_value"] == value

    @pytest.mark.parametrize("model_id,text_input,labels,value", ZERO_SHOT_MODELS)
    @pytest.mark.skip("temp skip")
    def test_zero_shot_classification(self, model_id, text_input, labels, value):
        with tempfile.TemporaryDirectory() as tmp_dir:
            ptm = download_model_and_start_deployment(
                tmp_dir, True, model_id, "zero_shot_classification"
            )
            result = ptm.infer(
                {
                    "docs": [{"text_field": text_input}],
                    "inference_config": {
                        "zero_shot_classification": {"labels": labels}
                    },
                }
            )
            assert result["predicted_value"] == value

    @pytest.mark.parametrize("quantize,model_id,text_input,value", TEXT_EMBEDDING)
    @pytest.mark.skip("temp skip")
    def test_text_embedding(self, quantize, model_id, text_input, value):
        with tempfile.TemporaryDirectory() as tmp_dir:
            ptm = download_model_and_start_deployment(
                tmp_dir, quantize, model_id, "text_embedding"
            )
            result = ptm.infer({"docs": [{"text_field": text_input}]})
            np.testing.assert_almost_equal(result["predicted_value"], value, decimal=2)
